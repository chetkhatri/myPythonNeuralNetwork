{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-requisites\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a neural network in python\n",
    "\n",
    "Firstly, a neural network is defined by the number of layers, and the number of neurons in each layer.\n",
    "\n",
    "Let us use a list to denote this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jwifhiwfn\n"
     ]
    }
   ],
   "source": [
    "# Defining the sizes of the layers in our neural network\n",
    "layers = [2, 2, 1]\n",
    "print(\"jwifhiwfn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code denotes the 3-neuron neural network we saw previously: 2-dimensional input, 2 neurons in a hidden layer, 1 neuron in the output layer.\n",
    "\n",
    "Generally speaking, a neural network than has more than 1 hidden layer is a **deep** neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining weight matrices\n",
    "\n",
    "Using the sizes of the layers in our neural network, let us initialize the weight matrices to random values (sampled from a standard normal gaussian, because we know that we need both positive and negative weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing weight matrices from layer sizes\n",
    "def initializeWeights(layers):\n",
    "    weights = [np.random.randn(o, i+1) for i, o in zip(layers[:-1], layers[1:])]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(2, 3)\n",
      "[[ 0.45147937  2.36764603 -0.44038386]\n",
      " [ 1.25899973 -1.06551598  0.20563357]]\n",
      "2\n",
      "(1, 3)\n",
      "[[-0.76261718 -0.90078965 -0.01774495]]\n"
     ]
    }
   ],
   "source": [
    "# Displaying weight matrices\n",
    "layers = [2, 2, 1]\n",
    "weights = initializeWeights(layers)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    print(i+1); print(weights[i].shape); print(weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "\n",
    "The output of the neural network is calculated by **propagating forward** the outputs of each layer.\n",
    "\n",
    "Let us define our input as an np.array, since we want to represent matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We shall use np.array() to represent matrices\n",
    "#X = np.array([23, 42, 56])\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding bias terms\n",
    "\n",
    "Since the input to every layer needs a bias term (1) added to it, let us define a function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a bias term to every data point in the input\n",
    "def addBiasTerms(X):\n",
    "        # Make the input an np.array()\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Forcing 1D vectors to be 2D matrices of 1xlength dimensions\n",
    "        if X.ndim==1:\n",
    "            X = np.reshape(X, (1, len(X)))\n",
    "        \n",
    "        # Inserting bias terms\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell to test the addBiasTerms function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding bias terms: \n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "After adding bias terms: \n",
      "[[1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# TESTING addBiasTerms\n",
    "\n",
    "# We shall use np.array() to represent matrices\n",
    "#X = np.array([23, 42, 56])\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "print(\"Before adding bias terms: \"); print(X)\n",
    "X = addBiasTerms(X)\n",
    "print(\"After adding bias terms: \"); print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "Let us also define a function to calculate the sigmoid of any np.array given to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(a):\n",
    "    return 1/(1 + np.exp(-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation of inputs\n",
    "\n",
    "Let us store the outputs of the layers in a list called \"outputs\". We shall use that the output of one layer as the input to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward Propagation of outputs\n",
    "def forwardProp(X, weights):\n",
    "    # Initializing an empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Assigning a name to reuse as inputs\n",
    "    inputs = X\n",
    "    \n",
    "    # For each layer\n",
    "    for w in weights:\n",
    "        # Add bias term to input\n",
    "        inputs = addBiasTerms(inputs)\n",
    "        \n",
    "        # Y = Sigmoid ( X .* W^T )\n",
    "        outputs.append(sigmoid(np.dot(inputs, w.T)))\n",
    "        \n",
    "        # Input of next layer is output of this layer\n",
    "        inputs = outputs[-1]\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following cell to test forward propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:\n",
      "1\n",
      "(2, 3)\n",
      "[[-250  350  350]\n",
      " [-250  200  200]]\n",
      "2\n",
      "(1, 3)\n",
      "[[-100  500 -500]]\n",
      "X:\n",
      "[[0, 0], [0, 1], [1, 0], [1, 1]]\n",
      "outputs:\n",
      "1\n",
      "(4, 2)\n",
      "[[  2.66919022e-109   2.66919022e-109]\n",
      " [  1.00000000e+000   1.92874985e-022]\n",
      " [  1.00000000e+000   1.92874985e-022]\n",
      " [  1.00000000e+000   1.00000000e+000]]\n",
      "2\n",
      "(4, 1)\n",
      "[[  3.72007598e-44]\n",
      " [  1.00000000e+00]\n",
      " [  1.00000000e+00]\n",
      " [  3.72007598e-44]]\n"
     ]
    }
   ],
   "source": [
    "# VIEWING FORWARD PROPAGATION\n",
    "\n",
    "# Initialize network\n",
    "layers = [2, 2, 1]\n",
    "#weights = initializeWeights(layers)\n",
    "\n",
    "# 3-neuron network\n",
    "weights = []\n",
    "weights.append(np.array([[-250, 350, 350], [-250, 200, 200]]))\n",
    "weights.append(np.array([[-100, 500, -500]]))\n",
    "\n",
    "print(\"weights:\")\n",
    "for i in range(len(weights)):\n",
    "    print(i+1); print(weights[i].shape); print(weights[i])\n",
    "\n",
    "# Input\n",
    "X = [[0,0], [0,1], [1,0], [1,1]]\n",
    "\n",
    "print(\"X:\"); print(X)\n",
    "\n",
    "# Forward propagate X, and save outputs\n",
    "outputs = forwardProp(X, weights)\n",
    "\n",
    "print(\"outputs:\")\n",
    "for o in range(len(outputs)):\n",
    "    print(o+1); print(outputs[o].shape); print(outputs[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
